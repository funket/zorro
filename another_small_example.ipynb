{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T8KuPgslQ-CV"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup in google colab\n",
    "\n",
    "Uncomment the code in the following cells to use this notebook in google colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nv6x1s15RB-D",
    "outputId": "6bff7b91-c7a1-46d2-daa1-532bc3c8a315"
   },
   "outputs": [],
   "source": [
    "# def format_pytorch_version(version):\n",
    "#   return version.split('+')[0]\n",
    "#\n",
    "# TORCH_version = torch.__version__\n",
    "# TORCH = format_pytorch_version(TORCH_version)\n",
    "#\n",
    "# def format_cuda_version(version):\n",
    "#   return 'cu' + version.replace('.', '')\n",
    "#\n",
    "# CUDA_version = torch.version.cuda\n",
    "# CUDA = \"cpu\"\n",
    "#\n",
    "# !pip install torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "# !pip install torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "# !pip install torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "# !pip install torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
    "# !pip install torch-geometric\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sk-fKWz6RO9M",
    "outputId": "650ab4d3-45e2-4d88-91e9-7095a32d5abb"
   },
   "outputs": [],
   "source": [
    "# !git clone https://github.com/funket/zorro.git\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-oXUDeOyRgt4",
    "outputId": "bc2c1be3-89a0-4bf9-8e52-444d113d12a8"
   },
   "outputs": [],
   "source": [
    "# !pwd\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_Eo-J8SYRicX",
    "outputId": "6004253a-2dcc-4763-8634-e0d7ae0db0d8"
   },
   "outputs": [],
   "source": [
    "# %cd zorro/\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WT0kEgBuRnvt",
    "outputId": "214699ba-151e-4bc7-a100-56552b16fc31"
   },
   "outputs": [],
   "source": [
    "# !pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y_qfpRevQ8wm"
   },
   "outputs": [],
   "source": [
    "from explainer import *\n",
    "from models import *\n",
    "import torch\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Ik8h53wQ8wr"
   },
   "source": [
    "# Data loading and GNN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7m1OlRIAQ8wt",
    "outputId": "7c0201db-4530-42c4-9f4a-1787480b2705",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "dataset, data, results_path = load_dataset(\"Cora\")\n",
    "model = GCNNet(dataset)\n",
    "model.to(device)\n",
    "data = data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e5bNvZzmQ8wu",
    "outputId": "76c6e660-5dfc-45d3-f62f-14a62495823f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_model(model, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Ifr8w0JQ8wv"
   },
   "source": [
    "# Gradient based explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4FaYbl62Q8ww",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from gnn_explainer import GNNExplainer\n",
    "\n",
    "# GNNExplainer class needed for retrieval of computational graph\n",
    "gnn_explainer = GNNExplainer(model, log=False)\n",
    "\n",
    "explain_node = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVtGOuIIQ8wx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def execute_model_with_gradient(model, node, x, edge_index):\n",
    "    \"\"\"Helper function, which mainly does a forward pass of the GNN\"\"\"\n",
    "    ypred = model(x, edge_index)\n",
    "\n",
    "    predicted_labels = ypred.argmax(dim=-1)\n",
    "    predicted_label = predicted_labels[node]\n",
    "    logit = torch.nn.functional.softmax((ypred[node, :]).squeeze(), dim=0)\n",
    "\n",
    "    logit = logit[predicted_label]\n",
    "    loss = -torch.log(logit)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CppOdP6NQ8wx",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_grad_node_explanation(model, node, data):\n",
    "    \"\"\"Calculates the gradient feature and node explanation\"\"\"\n",
    "\n",
    "    # retrieve computational graph\n",
    "    computation_graph_feature_matrix, computation_graph_edge_index, mapping, hard_edge_mask, kwargs = \\\n",
    "                                    gnn_explainer.__subgraph__(node, data.x, data.edge_index)\n",
    "    # from now only work on the computational graph\n",
    "    x = computation_graph_feature_matrix\n",
    "    edge_index = computation_graph_edge_index\n",
    "\n",
    "    # create a mask of ones which will be differentiated\n",
    "    num_nodes, num_features = x.size()\n",
    "    node_grad = torch.nn.Parameter(torch.ones(num_nodes, device=x.device))\n",
    "    feature_grad = torch.nn.Parameter(torch.ones(num_features, device=x.device))\n",
    "    node_grad.requires_grad = True\n",
    "    feature_grad.requires_grad = True\n",
    "    mask = node_grad.unsqueeze(0).T.matmul(feature_grad.unsqueeze(0))\n",
    "\n",
    "    model.zero_grad()\n",
    "    execute_model_with_gradient(model, mapping, mask*x, edge_index)\n",
    "\n",
    "    node_mask = torch.abs(node_grad.grad).cpu().detach().numpy()\n",
    "    feature_mask = torch.abs(feature_grad.grad).cpu().detach().numpy()\n",
    "\n",
    "    return feature_mask, node_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmjUCbApRwpe",
    "outputId": "0742718e-0231-4e3d-8e8d-44676f5087b2"
   },
   "outputs": [],
   "source": [
    "grad_explanation = get_grad_node_explanation(model, explain_node, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of Feature mask\")\n",
    "plt.hist(grad_explanation[0])\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtBkV46GQ8wz"
   },
   "source": [
    "##### Possible task: implementation of GradInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "55Htke8YQ8wz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2qM-yixWQ8wz"
   },
   "source": [
    "# GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-y8VWKjhQ8w0",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_gnn_explainer(node, data):\n",
    "    feature_mask, edge_mask = gnn_explainer.explain_node(node, data.x, data.edge_index)\n",
    "    return feature_mask, edge_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5BRP2rGR1Wx",
    "outputId": "f5c38cec-b10f-453d-9f0e-11896871a683"
   },
   "outputs": [],
   "source": [
    "gnn_explanation = get_gnn_explainer(explain_node, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of Feature mask\")\n",
    "plt.hist(gnn_explanation[0])\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Az3xEGHASQrz"
   },
   "source": [
    "# Zorro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMbIchxVSSva"
   },
   "outputs": [],
   "source": [
    "from explainer import Zorro\n",
    "\n",
    "zorro = Zorro(model, device)\n",
    "def get_zorro(node):\n",
    "    # Same as the 0.98 in the paper\n",
    "    tau = .03\n",
    "    # only retrieve 1 explanation\n",
    "    recursion_depth = 1\n",
    "\n",
    "    explanation = zorro.explain_node(node, data.x, data.edge_index, tau=tau, recursion_depth=recursion_depth,)\n",
    "\n",
    "    selected_nodes, selected_features, executed_selections = explanation[0]\n",
    "\n",
    "    return selected_features[0], selected_nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RSXLOLDATCDo",
    "outputId": "2f592425-203b-4338-abd7-c9250b972670"
   },
   "outputs": [],
   "source": [
    "zorro_explanation = get_zorro(explain_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of Feature mask\")\n",
    "plt.hist(zorro_explanation[0])\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SoftZorro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from explainer import SoftZorro\n",
    "\n",
    "soft_zorro = SoftZorro(model, device)\n",
    "\n",
    "def get_soft_zorro(node):\n",
    "    node_mask, feature_mask = soft_zorro.explain_node(node, data.x, data.edge_index)\n",
    "    return feature_mask[0], node_mask[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "soft_zorro_explanation = get_soft_zorro(explain_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.title(\"Distribution of Feature mask\")\n",
    "plt.hist(soft_zorro_explanation[0])\n",
    "plt.yscale(\"log\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "xaiss_hands_on_xai_gnn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}